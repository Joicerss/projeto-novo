# Coletor Automatizado de Dados Judiciais

Sistema automatizado para coleta de dados de processos judiciais de recupera√ß√£o judicial envolvendo o banco Ita√∫ e empresas do setor de ve√≠culos pesados nos Tribunais de Justi√ßa brasileiros.

## üìã Descri√ß√£o

Este projeto automatiza a coleta de dados de processos judiciais para responder quest√µes espec√≠ficas sobre recupera√ß√£o judicial no setor de ve√≠culos pesados, incluindo:

1. Principais motivos que levam empresas do setor a entrarem em recupera√ß√£o judicial
2. Taxa de sucesso das recupera√ß√µes judiciais neste setor
3. Tempo m√©dio de tramita√ß√£o dos processos
4. Garantias mais comumente oferecidas
5. Papel dos bancos (especialmente Ita√∫) nesses processos
6. Principais credores al√©m dos bancos
7. Padr√µes regionais ou temporais nos pedidos de recupera√ß√£o

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Instala√ß√£o das depend√™ncias

```bash
# No diret√≥rio raiz do projeto
pip install -r requirements.txt
```

### Depend√™ncias opcionais

Para recursos avan√ßados de scraping (se necess√°rio):

```bash
# Instalar Playwright (navegador headless)
playwright install chromium

# Para OCR (se processos tiverem PDFs escaneados)
# pip install pytesseract Pillow
# E instalar Tesseract-OCR no sistema
```

## üìÅ Estrutura do Projeto

```
coleta_judicial/
‚îÇ
‚îú‚îÄ‚îÄ __init__.py              # Inicializa√ß√£o do pacote
‚îú‚îÄ‚îÄ config.py                # Configura√ß√µes (bancos, tribunais, datas)
‚îú‚îÄ‚îÄ base_scraper.py          # Classe base para scrapers
‚îú‚îÄ‚îÄ tjsp_scraper.py          # Scraper espec√≠fico para TJSP
‚îú‚îÄ‚îÄ data_exporter.py         # Exporta√ß√£o de dados (CSV, JSON, Excel)
‚îú‚îÄ‚îÄ main_collector.py        # Script principal de orquestra√ß√£o
‚îî‚îÄ‚îÄ README.md                # Esta documenta√ß√£o

resultados_coleta/           # Diret√≥rio criado automaticamente
‚îú‚îÄ‚îÄ processos_YYYYMMDD_HHMMSS.csv
‚îú‚îÄ‚îÄ processos_YYYYMMDD_HHMMSS.json
‚îî‚îÄ‚îÄ resumo_coleta.txt
```

## üîß Configura√ß√£o

Edite o arquivo `config.py` para personalizar:

- **BANKS**: Lista de bancos a buscar (padr√£o: Ita√∫)
- **KEYWORDS**: Palavras-chave de busca (recupera√ß√£o judicial, ve√≠culos pesados, etc.)
- **TRIBUNALS**: Tribunais a consultar (TJSP configurado, outros podem ser adicionados)
- **DATE_START/DATE_END**: Per√≠odo de busca
- **OUTPUT_FORMAT**: Formato de sa√≠da (csv, json, xlsx)

## üèÉ Uso

### Execu√ß√£o b√°sica

```bash
cd coleta_judicial
python main_collector.py
```

### Execu√ß√£o program√°tica

```python
from coleta_judicial import JudicialDataCollector

collector = JudicialDataCollector()
collector.run()
```

### Uso individual de componentes

```python
# Usar apenas o scraper do TJSP
from coleta_judicial import TJSPScraper

scraper = TJSPScraper(
    search_url="https://esaj.tjsp.jus.br/cjsg/consultaCompleta.do",
    timeout=30
)

results = scraper.search_processes(
    keywords=["recupera√ß√£o judicial", "Ita√∫"],
    date_start="01/01/2023",
    date_end="31/12/2025"
)

# Exportar resultados
from coleta_judicial import DataExporter

exporter = DataExporter(output_dir="meus_resultados")
exporter.export_to_csv(results, "processos_tjsp.csv")
```

## üìä Formatos de Sa√≠da

### CSV
Formato tabular simples, ideal para an√°lise em Excel ou ferramentas estat√≠sticas.

### JSON
Formato estruturado completo, preserva hierarquias (partes, movimenta√ß√µes).

### Excel (XLSX)
Formato formatado com colunas ajustadas automaticamente.

## ‚öôÔ∏è Funcionalidades

### Implementadas

- ‚úÖ Estrutura base de scraping com retry e timeout
- ‚úÖ Configura√ß√£o centralizada e flex√≠vel
- ‚úÖ Scraper template para TJSP
- ‚úÖ Exporta√ß√£o em m√∫ltiplos formatos (CSV, JSON, Excel)
- ‚úÖ Logging detalhado de opera√ß√µes
- ‚úÖ Tratamento de erros robusto
- ‚úÖ Sistema modular e extens√≠vel

### A implementar (requer an√°lise da estrutura real dos sites)

- ‚è≥ Implementa√ß√£o completa da l√≥gica de busca no TJSP
- ‚è≥ Parser de HTML espec√≠fico para TJSP
- ‚è≥ Scrapers para outros tribunais (TJRJ, TJMG, etc.)
- ‚è≥ Tratamento de CAPTCHA
- ‚è≥ Navega√ß√£o de pagina√ß√£o
- ‚è≥ Extra√ß√£o de PDFs e anexos
- ‚è≥ Cache de resultados

## üîç Observa√ß√µes Importantes

### Aspectos Legais e √âticos

1. **Respeite o robots.txt**: Verifique as pol√≠ticas de acesso de cada tribunal
2. **Rate limiting**: O sistema inclui delays entre requisi√ß√µes
3. **Dados p√∫blicos**: Colete apenas dados p√∫blicos dispon√≠veis
4. **LGPD**: Ao lidar com dados pessoais, siga a Lei Geral de Prote√ß√£o de Dados
5. **Uso respons√°vel**: N√£o sobrecarregue os servidores dos tribunais

### Limita√ß√µes T√©cnicas

1. **CAPTCHAs**: Muitos tribunais usam CAPTCHA - pode requerer interven√ß√£o manual ou servi√ßos de resolu√ß√£o
2. **JavaScript din√¢mico**: Alguns sites requerem Playwright/Selenium em vez de requests simples
3. **Estrutura HTML**: A estrutura dos sites pode mudar, requerendo atualiza√ß√£o dos parsers
4. **Acesso restrito**: Alguns dados podem requerer login/certificado digital

## üõ†Ô∏è Desenvolvimento

### Adicionar novo tribunal

1. Crie um novo arquivo `tj[SIGLA]_scraper.py`
2. Herde de `BaseJudicialScraper`
3. Implemente os m√©todos `search_processes` e `extract_process_info`
4. Adicione configura√ß√£o em `config.py`

Exemplo:

```python
from base_scraper import BaseJudicialScraper

class TJRJScraper(BaseJudicialScraper):
    def __init__(self, search_url, timeout=30):
        super().__init__('TJRJ', 'http://www4.tjrj.jus.br', timeout)
        self.search_url = search_url
    
    def search_processes(self, keywords, date_start, date_end):
        # Implementar l√≥gica espec√≠fica do TJRJ
        pass
```

### Executar testes

```bash
# Testar m√≥dulos individualmente
python -m coleta_judicial.base_scraper
python -m coleta_judicial.data_exporter

# Executar com dados de teste
python main_collector.py --test-mode
```

## üìù Logs

Os logs s√£o salvos em:
- Console (stdout)
- Arquivo `coleta_judicial.log`

N√≠veis de log:
- INFO: Opera√ß√µes normais
- WARNING: Avisos e situa√ß√µes incomuns
- ERROR: Erros que n√£o impedem a execu√ß√£o completa
- CRITICAL: Erros graves

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! √Åreas priorit√°rias:

1. Implementa√ß√£o completa dos parsers de tribunais
2. Tratamento de CAPTCHAs
3. Scrapers para tribunais adicionais
4. Testes automatizados
5. Documenta√ß√£o adicional

## üìÑ Licen√ßa

Este projeto √© desenvolvido para fins acad√™micos e de pesquisa em jurimetria.

## üìû Suporte

Para quest√µes ou problemas:
1. Verifique os logs em `coleta_judicial.log`
2. Consulte a documenta√ß√£o dos tribunais
3. Abra uma issue no reposit√≥rio

## üîÑ Pr√≥ximas Etapas

1. **An√°lise dos sites**: Inspecionar HTML real do TJSP e outros tribunais
2. **Implementa√ß√£o dos parsers**: Desenvolver l√≥gica espec√≠fica de extra√ß√£o
3. **Testes**: Validar com buscas reais
4. **Expans√£o**: Adicionar mais tribunais
5. **An√°lise de dados**: Processar dados coletados para responder as quest√µes de pesquisa

---

**Nota**: Este √© um sistema template. A implementa√ß√£o completa requer:
- An√°lise detalhada da estrutura HTML de cada tribunal
- Testes com dados reais
- Poss√≠vel uso de Selenium/Playwright para sites din√¢micos
- Tratamento de autentica√ß√£o e CAPTCHAs conforme necess√°rio
